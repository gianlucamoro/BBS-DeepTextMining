{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"Opinion Mining Lab - Exercises 2 (with solution).ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"z0aegAFNihDz"},"source":["# Opinion Mining & Sentiment Analysis: Exercises (part 2) Solution\n","\n","**Text Mining unit**\n","\n","_Prof. Gianluca Moro, Dott. Ing. Nicola Piscaglia – DISI, University of Bologna_\n","\n","**Bologna Business School** - Alma Mater Studiorum Università di Bologna"]},{"cell_type":"markdown","metadata":{"id":"C9sHk878uM5U"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"wlq0hdJOuWtn"},"source":["### Import libraries"]},{"cell_type":"code","metadata":{"id":"MVjtrtsuD3te"},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n","from statsmodels.stats.contingency_tables import mcnemar\n","import os\n","from urllib.request import urlretrieve\n","import glob\n","import gzip\n","import json"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oG8M1yTUX65e"},"source":["### Utility functions"]},{"cell_type":"code","metadata":{"id":"7JL5tJHlX4jr"},"source":["# Download a file from an URL\n","def download(file, url):\n","    if not os.path.isfile(file):\n","        urlretrieve(url, file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WbTxjuJBi6T8"},"source":["def scan_hu_liu(f):\n","    for line in f:\n","        line = line.decode(errors=\"ignore\").strip()\n","        if line and not line.startswith(\";\"):\n","            yield line\n","\n","def load_hu_liu(filename):\n","    with open(filename, \"rb\") as f:\n","        return set(scan_hu_liu(f))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mRnNzelIMreh"},"source":["total_samples = 50000\n","\n","def load_dataset(dataset_path):\n","    # We do not consider 3-stars rating as they can be confuse the model in\n","    # opinion polarity discrimination\n","    pos_overall_values = {5.0, 4.0}\n","    neg_overall_values = {1.0, 2.0}\n","    \n","    # Data structures\n","    data = []\n","    overall = []\n","\n","    # Data loading: read all the dataset\n","    print(\"Loading json file...\")\n","    \n","    # Reading dataset: we build our dataset by selecting\n","    # only the reviews which are not 3 stars rated. For each review added to our\n","    # dataset we add to \"overall\" the label for that review.\n","    with gzip.open(dataset_path) as jsonfile:\n","        index = 0\n","        pos = 0\n","        neg = 0\n","        # Each line in the json file represents a review\n","        for line in jsonfile:\n","            review = json.loads(line)\n","            # \n","            if review['overall'] in pos_overall_values and pos < int(total_samples / 2):\n","                index += 1\n","                # We keep track of the number of positive reviews read\n","                pos += 1\n","                # Review appending to our dataset\n","                data.append(review)\n","\n","                # Label appending\n","                overall.append(1)\n","                if index >= total_samples:\n","                    break\n","            elif review['overall'] in neg_overall_values and neg < int(total_samples / 2):\n","                index += 1\n","                # We keep track of the number of negative reviews read\n","                neg += 1\n","                data.append(review)\n","                # Label appending\n","                overall.append(0)\n","                # We stop reading if we reached the maximum number of samples\n","                if index >= total_samples:\n","                    break\n","\n","    df = pd.DataFrame.from_dict(data)[[\"reviewText\", \"overall\"]]\n","    df[\"reviewText\"] = df[\"reviewText\"].apply(lambda x: np.str_(x)) # encoding the strings as unicode ones\n","    df[\"overall\"] = np.where(df[\"overall\"] >= 4, 1, 0)\n","    return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"brPNp3uSldQC"},"source":["def mcnemar_pval(model1_predictions, model2_predictions):\n","    # define contingency table\n","    table = pd.crosstab(model1_predictions, model2_predictions)\n","    print(table)\n","\n","    # calculate mcnemar test\n","    result = mcnemar(table)\n","    return result.pvalue"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wnkMJMkxYA7F"},"source":["### Datasets Downloading"]},{"cell_type":"code","metadata":{"id":"IjkqeJGrrdH_"},"source":["# Dataset downloading\n","download('AMAZON_FASHION.json.gz','http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/AMAZON_FASHION.json.gz')\n","download(\"Software.json.gz\", \"http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/Software.json.gz\")\n","download(\"positive-words.txt\", \"https://raw.githubusercontent.com/unibodatascience/BBS-TextMining/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/positive-words.txt\")\n","download(\"negative-words.txt\", \"https://raw.githubusercontent.com/unibodatascience/BBS-TextMining/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/negative-words.txt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6YAjmHi5YHrG"},"source":["# Check if the files have been successfully downloaded\n","print(glob.glob(\"*\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wvsmOXnZY82_"},"source":["### Datasets loading"]},{"cell_type":"code","metadata":{"id":"4LrnAxV1P1c2"},"source":["pos_words = load_hu_liu(\"positive-words.txt\")\n","neg_words = load_hu_liu(\"negative-words.txt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jQHe-jEjzfgp"},"source":["# Loading data into a pandas dataframe\n","reviews = load_dataset('AMAZON_FASHION.json.gz')\n","reviews.head() # print first 5 entries"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KkWec0HHPztM"},"source":["reviews_B = load_dataset('Software.json.gz')\n","reviews_B.head() # print first 5 entries"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RvZ0WZAyywQu"},"source":["### Exercises"]},{"cell_type":"markdown","metadata":{"id":"GJADgDZFihEG"},"source":["1) Check the two loaded datasets cardinality and their distribution by label (`overall` field)"]},{"cell_type":"code","metadata":{"id":"RE2SDdnQihEH"},"source":["len(reviews)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ezs-EjjAFGbj"},"source":["len(reviews_B)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wfJ6yUxFihEQ"},"source":["reviews[\"overall\"].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y8E_G4nKSWi2"},"source":["reviews_B[\"overall\"].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RZUDfp1kC3Ea"},"source":["2) Then, randomly split the loaded dataset into training and test set\n","* using an hold-out approach (e.g. the training set is composed by the 70% of the dataset reviews)\n","* keeping the splits cardinality balanced by label"]},{"cell_type":"code","metadata":{"id":"HGKMd8dy33DW"},"source":["X_train, X_test, y_train, y_test = train_test_split(reviews[\"reviewText\"], reviews[\"overall\"], test_size = 0.3, random_state=42, stratify=reviews.overall)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"thNx8yxKTXIq"},"source":["y_train.value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wcvel0tHTZAo"},"source":["y_test.value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c357B6OmihEY"},"source":["3)  A lexicon with sets of commonly used positive and negative words is provided in the variables pos_words and neg_words, respectively.\n","\n","Setup NLTK and define the scoring function to classify all the reviews by first assigning to each a score equal to the number of known positive words within it minus the number of negative words, then return 1 for reviews with a positive score and 0 for reviews with a negative or null score."]},{"cell_type":"code","metadata":{"id":"bg56HNqgihEa"},"source":["import nltk\n","nltk.download(\"punkt\")\n","\n","def sentiment_score(review):\n","    tokens = nltk.word_tokenize(str(review))\n","    pos_count = sum(1 for t in tokens if t.lower() in pos_words)\n","    neg_count = sum(1 for t in tokens if t.lower() in neg_words)\n","    score = pos_count - neg_count\n","    return 1 if score > 0 else 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"za-2hKEAihEi"},"source":["4) Apply the function to all reviews contained in the test set of `review`\n","\n"]},{"cell_type":"code","metadata":{"id":"1uhhbRoMihEj"},"source":["preds_1 = X_test.apply(sentiment_score)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HQmMUoxBihEo"},"source":["5) Compare the obtained labels with the known ones and compute the accuracy as the ratio of matches"]},{"cell_type":"code","metadata":{"id":"LgyLbTEnihEo"},"source":["hits_1 = preds_1 == y_test\n","hits_1.mean()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NyroDWVoihEz"},"source":["6) Create a pipeline including a `CountVectorizer` to convert reviews into word count vectors and a `LogisticRegression` model"]},{"cell_type":"code","metadata":{"id":"RFqUhyBLihE0"},"source":["from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","\n","classifier_2 = Pipeline([\n","    (\"vect\", CountVectorizer(min_df=3)),\n","    (\"logreg\", LogisticRegression(max_iter=500))\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9qy6cAiuihE5"},"source":["7) Train the model on the training set of the `review` dataset "]},{"cell_type":"code","metadata":{"id":"29L6ZQXIihE6"},"source":["classifier_2.fit(X_train, y_train);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RdC3yKxxihFC"},"source":["8) Evaluate the model on the test set of the `review` dataset "]},{"cell_type":"code","metadata":{"id":"sHsQrQtvihFD"},"source":["classifier_2.score(X_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Crs7chcBihFP"},"source":["9) Repeat steps from 6 to 8, but replacing the `CountVectorizer` in the pipeline with a `TfidfVectorizer`"]},{"cell_type":"code","metadata":{"id":"YO6iXWhUihFR"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","classifier_3 = Pipeline([\n","    (\"vect\", TfidfVectorizer(min_df=3)),\n","    (\"logreg\", LogisticRegression(max_iter=500))\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GLxXlAv9ihFY"},"source":["classifier_3.fit(X_train, y_train);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iPwdIklGihFh"},"source":["classifier_3.score(X_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1SCmzFpYihFm"},"source":["10) Repeat steps from 6 to 8, as above, but set the `ngram_range` parameter of the `TfidfVectorizer` to include bigrams"]},{"cell_type":"code","metadata":{"id":"Y-z1tOlDihFn"},"source":["classifier_4 = Pipeline([\n","    (\"vect\", TfidfVectorizer(min_df=3, ngram_range=(1, 2))),\n","    (\"logreg\", LogisticRegression())\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rOJx9K7lihFr"},"source":["classifier_4.fit(X_train, y_train);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VoJeIXDmihFx"},"source":["classifier_4.score(X_test, y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Z8-7qwTihF4"},"source":["11) Repeat the evaluation phase of the three models above, this time on all the reviews from `reviews_B` dataset"]},{"cell_type":"code","metadata":{"id":"jH-beNlNihF4"},"source":["classifier_2.score(reviews_B[\"reviewText\"], reviews_B[\"overall\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rp_42oexihF9"},"source":["classifier_3.score(reviews_B[\"reviewText\"], reviews_B[\"overall\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"njVma5amihGD"},"source":["classifier_4.score(reviews_B[\"reviewText\"], reviews_B[\"overall\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WfWZY_hUihGI"},"source":["12) Extract the predictions from `reviews` test set for each classifier: we already have those for the unsupervised one (`preds_1`), we need those from the supervised models"]},{"cell_type":"code","metadata":{"id":"UVbJeAT6ihGI"},"source":["preds_2 = classifier_2.predict(X_test)\n","preds_3 = classifier_3.predict(X_test)\n","preds_4 = classifier_4.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p-IJ0MF3ihGM"},"source":["13) Perform comparisons between every pair of models using the provided `mcnemar_pval(p1, p2)` function"]},{"cell_type":"markdown","metadata":{"id":"XkEokwmktSlW"},"source":["Set a confidence level to consider for rejecting the null hypothesis (H0) e.g. 95%.\n","\n","H0 states the two classifiers present the same proportions of errors (they disagree to the same amount)."]},{"cell_type":"markdown","metadata":{"id":"AOX6S2ApihGk"},"source":["**In each case, the closer the p-value to 0, the more compared classifiers are different**"]},{"cell_type":"code","metadata":{"id":"_WUC3L8MihGN"},"source":["pvalue_1_2 = mcnemar_pval(preds_1, preds_2)\n","pvalue_1_2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PPUFyCe8qihq"},"source":["confidence_level = 0.95 # The probability that if the test were repeated over and over again, the results obtained would be the same\n","alpha = 1 - confidence_level # The significance level (alpha) is the probability of making the wrong decision when the null hypothesis is true\n","\n","def are_models_similar(pvalue, alpha):\n","  print(\"alpha: \" + str(alpha))\n","  print(\"pvalue: \" + str(pvalue))\n","  if pvalue > alpha:\n","\t  print('Same/Similar proportions of errors (fail to reject H0)')\n","  else:\n","\t  print('Different proportions of errors (reject H0)') # H0 states the two classifiers present the same proportions of errors"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lAaOmE0eZUFW"},"source":["are_models_similar(pvalue_1_2, alpha) # a pvalue of 0.0005 means that there is a probability of 0.05% to falsely reject the null hypothesis (i.e 0.05% probability that the two models are similar)\n","\n","pd.crosstab(preds_1, preds_2) # Computes the contingency table"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"22c-d1O-ihGR"},"source":["pvalue = mcnemar_pval(preds_1, preds_3)\n","\n","are_models_similar(pvalue, alpha)\n","\n","pd.crosstab(preds_1, preds_3) # Computes the contingency table"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Vbe9_eBihGW"},"source":["pvalue = mcnemar_pval(preds_1, preds_4)\n","\n","are_models_similar(pvalue, alpha)\n","\n","pd.crosstab(preds_1, preds_4) # Computes the contingency table"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XaCwjwptihGa"},"source":["pvalue = mcnemar_pval(preds_2, preds_3)\n","\n","are_models_similar(pvalue, alpha)\n","\n","pd.crosstab(preds_2, preds_3) # Computes the contingency table"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OidyvH-3ihGe"},"source":["pvalue = mcnemar_pval(preds_2, preds_4)\n","\n","are_models_similar(pvalue, alpha)\n","\n","pd.crosstab(preds_2, preds_4) # Computes the contingency table"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sLwnL8jaihGh"},"source":["pvalue = mcnemar_pval(preds_3, preds_4)\n","\n","are_models_similar(pvalue, alpha)\n","\n","pd.crosstab(preds_3, preds_4) # Computes the contingency table"],"execution_count":null,"outputs":[]}]}